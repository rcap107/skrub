"""
.. _example_datetime_encoder :

===============================================================
Timeseries forecasting with DatetimeEncoder and lagged features
===============================================================

In this example, we illustrate how combine the datetime features generated by the
|DatetimeEncoder| with the skrub expressions to forecast the the demand for bike
rentals over time.

For the sake of the example, we will use a simple linear model (|RidgeCV|) to
predict the demand in order to highlight the impact of the
datetime features on the prediction performance.

.. |DatetimeEncoder| replace::
    :class:`~skrub.DatetimeEncoder`

.. |TableVectorizer| replace::
    :class:`~skrub.TableVectorizer`

.. |Cleaner| replace::
    :class:`~skrub.Cleaner`

.. |OneHotEncoder| replace::
    :class:`~sklearn.preprocessing.OneHotEncoder`

.. |TimeSeriesSplit| replace::
    :class:`~sklearn.model_selection.TimeSeriesSplit`

.. |ColumnTransformer| replace::
    :class:`~sklearn.compose.ColumnTransformer`

.. |make_column_transformer| replace::
    :class:`~sklearn.compose.make_column_transformer`

.. |RidgeCV| replace::
    :class:`~sklearn.linear_model.RidgeCV`

.. |SimpleImputer| replace::
    :class:`~sklearn.impute.SimpleImputer`

.. |StandardScaler| replace::
    :class:`~sklearn.preprocessing.StandardScaler`

.. |ToDatetime| replace::
    :class:`~skrub.ToDatetime`

.. |var| replace::
    :meth:`~skrub.var`

.. |apply_func| replace::
    :meth:`~skrub.Expr.skb.apply_func`

.. |choose_bool| replace::
    :meth:`~skrub.choose_bool`

.. |choose_from| replace::
    :meth:`~skrub.choose_from`

.. |train_test_split| replace::
    :meth:`~skrub.Expr.skb.train_test_split`

.. |deferred| replace::
    :meth:`~skrub.deferred`

.. |.skb.subsample| replace::
    :meth:`~skrub.Expr.skb.subsample`

.. |TableReport| replace::
    :class:`~skrub.TableReport`

"""

# %%
# A problem with relevant datetime features
# -----------------------------------------
#
# We use a dataset of bike sharing demand in 2011 and 2012.
# In this setting, we want to predict the number of bike rentals, based
# on the date, time and weather conditions.
# In this example, we use Polars dataframes instead of Pandas.


import polars as pl

from skrub import datasets

data = datasets.fetch_bike_sharing().bike_sharing
data = pl.from_pandas(data)

# %%
# As first step, we use the skrub |TableReport| to explore the data and get an idea
# of the features we are working with.
# In particular, we can see that the dataset contains a "date" column, and that
# the "cnt" column is the target we want to predict. We can get a high level
# overview of the features in the dataset by checking out the ``Stats`` tab in the
# report. Among other things, we can see that the "date" column is a string column.
# This is potentially problematic, and a good use case for the skrub |DatetimeEncoder|,
# as we show in the rest of the example.

from skrub import TableReport

TableReport(data)


# %%
# Prediction with datetime features
# ---------------------------------
#
# In this section, we use the skrub |DatetimeEncoder|, paired with the skrub
# Expressions to build a predictive pipeline
# that pre-processes the data, performs feature engineering and executes
# hyperparameter optimization to improve the prediction performance.
# We will use a |RidgeCV| model as our learner. While it is not the most powerful
# model, it will help us illustrate how feature engineering affects the prediction
# performance.


from sklearn.linear_model import RidgeCV

# %%
# Since we are working with timeseries, we need to use |TimeSeriesSplit| to perform
# crossvalidation.
from sklearn.model_selection import TimeSeriesSplit
from sklearn.pipeline import make_pipeline

ts = TimeSeriesSplit(
    n_splits=3,  # to keep the notebook fast enough on common laptops
    gap=48,  # 2 days (48 hours) data gap between train and test
    max_train_size=10000,  # keep train sets of comparable sizes
    test_size=3000,  # for 2 or 3 digits of precision in scores
)


# %%
# We import ``skrub`` to access the skrub expressions and define a skrub |var|
# to start with. We use |.skb.subsample| to reduce the size of the dataset used
# in the preview to 100 rows, so that the notebook runs faster when developing.
# When the models are trained, the expressions switch automatically to the full
# dataset.

import skrub

data_var = skrub.var("data", data).skb.subsample(n=100)

# We extract our input data (``X``) and the target column (``y``), and mark them
# as X and y.
X = data_var[
    "date", "holiday", "weathersit", "temp", "hum", "windspeed"
].skb.mark_as_X()
y = data_var["cnt"].skb.mark_as_y()
X


# %%
# We can use the |Cleaner| to clean the data and convert the date column to a
# datetime column, as well as performing additional consistency and cleaning checks.
# The updated ``X`` dataframe will have the "date" column converted to a datetime.


from skrub import Cleaner

X = X.skb.apply(Cleaner())
X

# %%
# Now we define a simple default pipeline for the |RidgeCV| predictor, which includes
# a |StandardScaler| for numerical features and a |SimpleImputer| to handle
# missing values. We will not modify this pipeline: we will instead focus on
# pre-processing and feature engineering.

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

default_ridge_pipeline = make_pipeline(StandardScaler(), SimpleImputer(), RidgeCV())

# %%
# The "base" variant of the pipeline uses the default |TableVectorizer|, with
# no hyperparameter search. In this case, performing a grid-search is not
# necessary, but we will do it for consistency with the next steps.
# Note that in this case, the |TableVectorizer| repeats the same cleaning steps
# as the |Cleaner|: for consistency with the next steps, we retain the cleaned
# dataframe, but we could have used the original ``X`` dataframe instead.
# The ``vectorized`` dataframe now contains the original numerical features,
# while the ``date`` column has been converted to multiple columns, one for each
# part of the date (year, month, day, hour, etc.). All numerical columns are now
# float32.

from skrub import TableVectorizer

vectorized = X.skb.apply(TableVectorizer())
vectorized
# %%
predictions_base = vectorized.skb.apply(default_ridge_pipeline, y=y)
search_base = predictions_base.skb.get_grid_search(fitted=True, cv=ts)

# %%
# We can observe the results directly using ``.detailed_results_``. Unsurprisingly,
# the results are not very good. In this case, we are running a grid search with
# a single pipeline, so the results are not very informative. In the next steps,
# we introduce hyperparameter optimization, in which case the grid search will
# become more useful.


search_base.detailed_results_


# %%
# Prediction with periodic encoders and hyperparameter optimization
# -----------------------------------------------------------------
#
# The |DatetimeEncoder| can generate additional periodic features, which are
# particularly useful for linear models such as Ridge. Periodic features are off
# by default, but they can be enabled by setting the
# ``periodic encoding`` parameter to either  ``circular`` or ``spline``,
# for trigonometric functions or B-Splines respectively.
# Periodic features are added for each part of the date: hour in day, day in week,
# day in month, month in year.
# For our second pipeline, we define a grid of hyperparameters using the skrub
# ``choose_*`` functions. In this case, we use |choose_bool| and |choose_from|,
# as we are not interested in tweaking numerical parameters.
# The ``choose_*`` functions allow to easily prepare a grid of parameters to use
# to perform hyperparameter optimization.
# Here, we use them to turn on and off the ``weekday`` and ``total_seconds`` flag,
# and to select the specific periodic encoder to use.
# The new pipeline has the ending ``_feat_eng`` to indicate that it
# includes feature engineering steps.

from sklearn.pipeline import make_pipeline

import skrub.selectors as s
from skrub import DatetimeEncoder

datetime_encoder = DatetimeEncoder(
    add_weekday=skrub.choose_bool(name="weekday"),
    add_total_seconds=skrub.choose_bool(name="total_seconds"),
    periodic_encoding=skrub.choose_from(
        [
            "spline",
            "circular",
            None,
        ],
        name="periodic_encoding",
    ),
)


vectorized = X.skb.apply(datetime_encoder, cols=s.any_date())
predictions_rich_features = vectorized.skb.apply(default_ridge_pipeline, y=y)

# %%
# Note that, in general, randomized search should be used instead of grid search.
# In this case, grid search is fine as we are interested in a grid of categorical
# values.


search_rich_features = predictions_rich_features.skb.get_grid_search(fitted=True, cv=ts)


# %%
# We again observe the results of the grid search using ``.detailed_results_``.

search_rich_features.detailed_results_

# %%
# We may also use the parallel coordinate plot to visualize the impact of the
# hyperparameters on the prediction performance. It is possible to set a ``min_score``
# to filter out results that have score below the given threshold: in this case,
# we filter out result with a score below ``0.0``.

search_rich_features.plot_results(min_score=0.0)


# %%
# We can observe that the prediction results have improved a lot thanks to the
# introduction of the periodic features, however they are still not very good.
# We can also see that setting ``total_seconds`` to ``True`` seems to consistently
# reduce the test score.
#
# Adding lagged features
# ----------------------
#
# To further improve the prediction performance, we will extend the
# feature generation step to include lagged features.
# This function is taken from a similar
# `scikit-learn example <https://scikit-learn.org/stable/auto_examples/applications/plot_time_series_lagged_features.html#generating-polars-engineered-lagged-features>`_
# As the lagged
# features are based on the real count (i.e., the target feature), we go back to
# the original data to perform feature engineering on that.
#
# To introduce the lagged features, we use a |deferred| function that takes the
# dataframe we are working with, then adds lagged features to it. Given a sample
# in the dataset, lagged features add information relative to samples prior to it.
# In this case, for each hourly sample we add information relative to the previous
# three hours, the same hour on the prior day, as well as aggregate features
# (mean, max, min) obtained by using a rolling mean of either 24 hours, or 7 days.
#
# |deferred| functions delay the execution of the function until it is reached in
# the execution of the skrub expression. They allow arbitrary code to be executed,
# such as operations that leverage the Pandas or Polars API.


# %%
@skrub.deferred
def get_lagged_features(df):
    lagged_df = df.select(
        "cnt",
        *[pl.col("cnt").shift(i).alias(f"lagged_count_{i}h") for i in [1, 2, 3]],
        lagged_count_1d=pl.col("cnt").shift(24),
        lagged_count_1d_1h=pl.col("cnt").shift(24 + 1),
        lagged_count_7d=pl.col("cnt").shift(7 * 24),
        lagged_count_7d_1h=pl.col("cnt").shift(7 * 24 + 1),
        lagged_mean_24h=pl.col("cnt").shift(1).rolling_mean(24),
        lagged_max_24h=pl.col("cnt").shift(1).rolling_max(24),
        lagged_min_24h=pl.col("cnt").shift(1).rolling_min(24),
        lagged_mean_7d=pl.col("cnt").shift(1).rolling_mean(7 * 24),
        lagged_max_7d=pl.col("cnt").shift(1).rolling_max(7 * 24),
        lagged_min_7d=pl.col("cnt").shift(1).rolling_min(7 * 24),
    )
    return lagged_df


# %%
# To add lagged features to the data, we go back to the original ``data_var``, and
# drop the columns that are not relevant. We will have to clean the data again.


data_prep = data_var.drop("casual", "instant", "registered").skb.mark_as_X()
data_prep = data_prep.skb.apply(Cleaner())


# %%
# We can use the |apply_func| method to apply the lagged feature function
# to the data. The lagged features are added to the dataframe, and we can then
# concatenate them with the original data. This is done by using the ``.skb.concat``
# method, which concatenates the two dataframes along either the rows or the columns.
#
# Notice that adding lagged samples will introduce null values for all the initial
# samples, as there is no previous information for them.

data_lagged = data_prep.skb.apply_func(get_lagged_features).drop("cnt")
X = data_prep.skb.concat([data_lagged], axis=1).drop("cnt")
y = data_var["cnt"].skb.mark_as_y()
X


# %%
# We can use the datetime encoder defined above to observe the impact of the new
# features on the predictions.


vectorized = X.skb.apply(TableVectorizer(datetime=datetime_encoder))
predictions_lagged_features = vectorized.skb.apply(default_ridge_pipeline, y=y)
search_lagged_features = predictions_lagged_features.skb.get_grid_search(
    fitted=True, cv=ts
)
search_lagged_features.detailed_results_

# %%
search_lagged_features.plot_results(min_score=0.0)

# %%
# We can see that the lagged features improved the prediction performance by a
# large margin. Periodic features are still bringing some benefit.


# %%
# Plotting the prediction
# .......................
#
# To have a better idea of the quality of the predictions, we can plot them directly.
# We can use |train_test_split| to separate the data into a train split and
# a test split.
# In this case, we will use all the data for the year 2011 to predict year 2012.
# The |train_test_split| function can take a custom `splitter` function that returns
# the X and y splits based on some specific requirements; here, we specify a
# cutoff date and use that to prepare the train an test splits.
# For each pipeline, we run a grid search and select only the best pipeline according
# to its test score.
# Then, we train each pipeline on the training split and predict on the test split.


def split_function(X, y, cutoff=None):
    mask = X["date"] < cutoff
    X_train, X_test = X.filter(mask), X.filter(~mask)
    y_train, y_test = y.filter(mask), y.filter(~mask)
    return X_train, X_test, y_train, y_test


# %%
split_base = predictions_base.skb.train_test_split(
    environment=predictions_base.skb.get_data(),
    splitter=split_function,
    cutoff="2012-01-01",
)
search_base = predictions_base.skb.get_grid_search(
    cv=TimeSeriesSplit(), fitted=True
).fit(split_base["train"])
results_base = search_base.best_pipeline_.predict(split_base["test"])

split_feat_eng = predictions_rich_features.skb.train_test_split(
    environment=predictions_rich_features.skb.get_data(),
    splitter=split_function,
    cutoff="2012-01-01",
)
search_rich_features = predictions_rich_features.skb.get_grid_search(
    cv=TimeSeriesSplit(), fitted=True
).fit(split_feat_eng["train"])
results_rich_features = search_rich_features.best_pipeline_.predict(
    split_feat_eng["test"]
)

split_lagged = predictions_lagged_features.skb.train_test_split(
    environment=predictions_lagged_features.skb.get_data(),
    splitter=split_function,
    cutoff="2012-01-01",
)
search_lagged_features = predictions_lagged_features.skb.get_grid_search(
    cv=TimeSeriesSplit(), fitted=True
).fit(split_lagged["train"])
results_lagged_features = search_lagged_features.best_pipeline_.predict(
    split_lagged["test"]
)


# %%
# Now we can plot the results. For the sake of the example, we will consider only
# a single week in the year to be able to observe some details.


from datetime import datetime

import matplotlib.dates as mdates
import matplotlib.pyplot as plt
import pandas as pd

fig, ax = plt.subplots(figsize=(9, 3), layout="constrained")

X_plot = split_base["X_test"].select(pl.col("date").str.to_datetime())
y_true = split_base["y_test"]

# Preparing a dataframe with the results to simplify the plotting code
df_results = pd.DataFrame(
    {
        "date": X_plot.to_series(),
        "Actual demand": y_true,
        "Default DatetimeEncoder": results_base,
        "Periodic Features": results_rich_features,
        "Lagged + Periodic Features": results_lagged_features,
    }
)

df_results.set_index("date").plot(ax=ax, legend=None)

# Consider only the first week of November 2012.
ax.set_xlim([datetime(2012, 11, 1), datetime(2012, 11, 8)])
ax.set_ylim([0, 800])

# Format the x-axis
# Set the x-axis minor ticks to appear every 6 hours and the major ticks to appear
# every day.
ax.xaxis.set_major_formatter(mdates.DateFormatter("%a %d %b"))
ax.xaxis.set_minor_formatter(mdates.DateFormatter("%Hh"))
ax.xaxis.set_minor_locator(mdates.HourLocator(byhour=range(0, 24, 6)))
ax.xaxis.set_major_locator(mdates.DayLocator())
ax.tick_params(axis="x", which="minor", labelsize=8)
ax.tick_params(axis="x", which="major", pad=10)

ax.set_ylabel("Demand")
ax.set_xlabel("")

# Annotating the days that correspond to the weekend.
annotation_text = "Weekend"
ax.axvspan(
    datetime(2012, 11, 3), datetime(2012, 11, 5), color="grey", alpha=0.05, zorder=0
)
ax.text(
    datetime(2012, 11, 3),
    800,
    annotation_text,
    verticalalignment="top",
    horizontalalignment="left",
    fontsize=10,
    color="grey",
    fontweight="bold",
)

_ = fig.suptitle(
    (
        "Predicting the demand with linear models and different feature engineering"
        " strategies"
    ),
)

ax.legend(
    loc="upper right",
    # bbox_to_anchor=(0.5, 1.06),
    ncol=1,
    borderaxespad=0.0,
    frameon=True,
)


# %%
#
# As we can see, the pipeline that uses only the basic RidgeCV model does not
# follow the actual demand: it shows a periodic behavior that matches the days,
# but cannot model properly the peaks.
# The pipeline that includes periodic features is more accurate in modeling the peaks
# from rush hour, however it does not match the different behavior shown in the
# weekends, and it does not match the rush hour peaks either.
# Finally, the pipeline that includes lagged features tracks the actual demand
# very accurately, and is also able to follow the difference in demand on the
# weeekends.
#
#
# Summary
# ^^^^^^^
# In this example we have shown how to combine the Skrub DatetimeEncoder and the
# skrub expressions to perform feature engineering on dates: we generated periodic
# features, and we added lagged features to further extract information from the data.
# We also described how to use skrub expressions to generate hyperparameter grids,
# how to use deferred functions, and how to cross-validate models to produce
# results.
# Finally, we plotted the predictions to observe the effectiveness of the different
# preprocessing strategies.
